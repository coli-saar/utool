<?xml version="1.0" ?>

<examples>
	<example filename="chain3.clls"
		description="The pure chain of length 3" />
	
	<example filename="thatwould.clls"
		description="The MRS output (translated into a normal dominance constraint)
			that the English Resource Grammar (as of 2001) generates for
			the sentence &quot;But that would give us all day Tuesday to be there.&quot;
			This constraint has 64.764 solved forms. (Expect the solver to
			take a while to output all solutions to the constraint.)" />
	
	<example filename="rondane-1.mrs.pl"
		description="The MRS description of the Rondane Treebank (2005-02-15)
			sentence #1: &quot;The well-known and historic Aurlandsdalen Valley, was 
			once one of the main routes between the eastern and western 
            parts of Norway.&quot; This MRS has 675 solved forms (i.e. scopings), but is pretty
			hard for the standard LKB solver. Utool needs just a few
			milliseconds to solve it." />
	
	<example filename="rondane-1409.mrs.pl"
		description="The MRS description of the Rondane Treebank (2005-02-15)
        sentence #1409: &quot;Dinner is typically three courses: a soup, a main dish 
           and a light dessert.&quot; 
		This MRS has 48 solved forms (i.e. scopings), but is pretty
        hard for the standard LKB solver. Utool needs just a few
        milliseconds to solve it." />
	
	<example filename="rondane-650.mrs.pl"
		description="The MRS description of the Rondane Treebank (2005-02-15)
			sentence #650: 
	        &quot; Myrdal is the mountain terminus of the Flåm rail line (or
		    Flåmsbana) which makes its way down the lovely Flåm Valley
		    (Flåmsdalen) to its sea-level terminus at Flåm.&quot;
			This is the MRS with the most solved forms in the Rondane
			treebank; it has about 2.4 trillion solved forms. We estimate
			that utool would need more than a year to enumerate all these
			solved forms."/>
			
	<example filename="rondane-1262.mrs.pl"
		description="The MRS description of the Rondane Treebank (Jan 2006)
			sentence #1262:
			&quot; For travellers going to Finnmark there is a bus 
			service from Oslo to Alta through Sweden.&quot;
			According to the ERG annotation, this sentence has 3960 readings,
			but they only differ in the relative scope of proper names, and thus
			they are all semantically equivalent, and can be reduced by the
			redundany elimination algorithm." />
			
	<example filename="rondane-892.mrs.pl"
		description="The MRS description of the Rondane Treebank (Jan 2006)
			sentence #892:
			&quot;We quickly put up the tents in the lee of a 
			small hillside and cook for the first time in 
			the open.&quot;
			According to the ERG annotation, this sentence has 480 readings,
			but intuitively there are only two non-equivalent classes of
			readings, which are distinguished by the relative scope of
			&quot;the lee&quot; and &quot;a small hillside&quot;. The readings
			can be reduced by the redundancy elimination algorithm." />
	
	<example filename="holesemantics-14.hs.pl"
		description="A Hole Semantics USR from the Hole Semantics testsuite
			available as part of the software package at
			http://www.cogsci.ed.ac.uk/~jbos/comsem. This is a
			representation for the following sentence:

			   &quot;Every man in a restaurant knows a woman with a car.&quot;

	        The sentence has 14 readings. The solver described in the
		    Blackburn &amp; Bos textbook takes about 14 seconds to enumerate
			all pluggings. Utool needs about 10 milliseconds." />
			
	<example filename="kallmeyer-romero.clls"
		description="Example (37) from Kallmeyer &amp; Romero, Research on
		Language and Computation 2007.  This is an underspecified representation
		for the following sentence:
		
		      &quot;Two policement spy on someone from every city.&quot;
		      
		This graph is not weakly normal because of the cross edge from
		y1 to x3.  It has four solved forms." />

</examples>